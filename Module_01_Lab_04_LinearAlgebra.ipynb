{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maddalayasaswini/FMML_Lab_Modules/blob/main/Module_01_Lab_04_LinearAlgebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU9LZjQxiQT2"
      },
      "source": [
        "# Transforming data using linear algebra\n",
        "\n",
        "FMML Module 1, Lab 4<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "KBe4ZA32UTbv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mqG-dafVpya"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "from IPython.display import Latex as lt\n",
        "#Plotting functions\n",
        "#(You DON'T need to understand how these functions)\n",
        "\n",
        "# function to plot a grid\n",
        "def plotGrid(transform, unit, linestyle = ':', fig=None, ax=None):\n",
        "  lim1 = -100\n",
        "  lim2 = 100\n",
        "  def mat2xy(start, end):\n",
        "    if len(start.shape)==1:\n",
        "      start = np.expand_dims(start,0)\n",
        "      end = np.expand_dims(end,0)\n",
        "    nan = np.ones(len(start))*np.nan\n",
        "    x = np.stack((start[:,0], end[:,0], nan)).T.reshape(-1)\n",
        "    y = np.stack((start[:,1], end[:,1], nan)).T.reshape(-1)\n",
        "    return x, y\n",
        "\n",
        "  def parallellines(axis, addend, lines, unit):\n",
        "    addend = np.repeat(np.expand_dims(addend,0), lines*2, 0)\n",
        "    unit = np.expand_dims(np.arange(-lines, lines)*unit,1)\n",
        "    unit = unit-lines\n",
        "    addend = addend*unit\n",
        "    lines = np.expand_dims(axis,0) + addend\n",
        "    return np.concatenate((lines, lines*-1))\n",
        "\n",
        "  if fig is None:\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "  transform = transform.astype(np.float)\n",
        "  xaxis = transform[0]\n",
        "  yaxis = transform[1]\n",
        "\n",
        "  # plot lines parallel to the x axis\n",
        "  lines1= parallellines(xaxis*lim1, yaxis, 100,unit )\n",
        "  lines2 = parallellines(xaxis*lim2, yaxis, 100,unit )\n",
        "  x,y = mat2xy(lines1, lines2)\n",
        "  plt.plot(x,y, linestyle+'k', linewidth=0.5)\n",
        "  # plot x axis\n",
        "  x,y = mat2xy(xaxis*lim1, xaxis*lim2)\n",
        "  plt.plot(x,y,linestyle, color = '#440077')\n",
        "\n",
        "  # plot  lines parallel to the y axis\n",
        "  lines1= parallellines(yaxis*lim1, xaxis, 100,unit)\n",
        "  lines2 = parallellines(yaxis*lim2, xaxis, 100,unit)\n",
        "  x,y = mat2xy(lines1, lines2)\n",
        "  plt.plot(x,y, linestyle+'k', linewidth=0.5)\n",
        "  # plot y axis\n",
        "  x,y = mat2xy(yaxis*lim1, yaxis*lim2)\n",
        "  plt.plot(x,y,linestyle, color= '#aa5500')\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "def plotData(X, y, xlabel = 'hole', ylabel = 'bound', fig=None, ax = None):\n",
        "\n",
        "  if fig is None:\n",
        "    fig, ax = plt.subplots()\n",
        "  for ii in range(nclasses):\n",
        "    plt.scatter(X[y==ii,0], X[y==ii, 1])\n",
        "  plt.legend([str(i) for i in range(nclasses)])\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  lim2 = X.max()\n",
        "  lim1 = X.min()\n",
        "  add = abs(lim1-lim2)/5\n",
        "  return fig, ax\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5dmEXxaktp"
      },
      "source": [
        "# Matrix transformations on data\n",
        "\n",
        "A 2D coordinate system is defined by its basis vectors, i and j. In the standard coordinate system (Let us call it T0), the basis vectors are\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ 0 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 1\\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "We can use any two vectors as basis vectors for a new coordinate system as long as they are not colinear. For example, let us call this new coordinate system T1:\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ -1 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 2 \\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "Suppose we have a point [a,b] in the T1 coordinate system. Its representation in the standard system T0 can be obtained by the following matrix multiplication:\n",
        "\n",
        "$$ \\begin{equation}\n",
        "\\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        "\\left\\{  \\begin{aligned}&1 & 0 \\\\ -&1 & 2 \\end{aligned} \\right\\}\n",
        "\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "where the columns of the matrix are the basis vectors of T1.\n",
        "\n",
        "Let us see this in action:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8SCFKqfbM-l"
      },
      "outputs": [],
      "source": [
        "T0 = np.array([[1,0],[0,1]])\n",
        "T1 = np.array([[1,0], [-1,2]])\n",
        "\n",
        "data1 = np.array([5,4]) # the data in T1 coordinate system\n",
        "data0 = np.matmul(T1, data1) # the data in T0 coordinate system\n",
        "\n",
        "print('Data in T0 = ', data0)\n",
        "print('Data in T1 = ', data1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfEWZ1RQeve"
      },
      "source": [
        "We can visualize this below. T0 is shown with dotted lines and T1 is shown with solid lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSuTaeSDQoYK"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotGrid(T1.T, 1,'-') # custom plotting function, no need to understand this\n",
        "plotGrid(T0.T, 1, fig=fig, ax=ax) # custom plotting function, no need to understand this\n",
        "plt.scatter(data0[0], data0[1])\n",
        "ax.set_xlim(-10,10)\n",
        "ax.set_ylim(-10,10)\n",
        "ax.set_xticks([]);\n",
        "ax.set_yticks([]);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUb3oYWIgdya"
      },
      "source": [
        "Look at the coordinates of the blue dot. In T0 (dotted lines), the position is [5,3] where it is [5,4] in T1. Feel free to experiment with different data points and coordinate systems.\n",
        "\n",
        "Remember that we can achieve the same thing by post-multiplying the transpose of the transformation matrix to the data. This will come in handy when transforming multiple data points at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD4pqOMndf-4"
      },
      "outputs": [],
      "source": [
        "data0_a = np.matmul(T1, data1)\n",
        "data0_b = np.matmul(data1, T1.T)\n",
        "print(data0_a)\n",
        "print(data0_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Kui3dSESPm"
      },
      "source": [
        "Why is transforming data useful? Data transformations cause the distance between data points to change. This will affect distance-based algorithms such as nearest neighbour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE0NbpYIC9ou"
      },
      "outputs": [],
      "source": [
        "# let us define 3 points in T1\n",
        "A1 = np.array([3,3])\n",
        "B1 = np.array([2,-5])\n",
        "C1 = np.array([1,-1])\n",
        "\n",
        "# the corresponding points in T0:\n",
        "A0 = np.matmul(T1, A1)\n",
        "B0 = np.matmul(T1, B1)\n",
        "C0 = np.matmul(T1, C1)\n",
        "\n",
        "# function to calculate Euclidean distance:\n",
        "def dist(a, b):\n",
        "  diff = a-b\n",
        "  sq = diff*diff\n",
        "  return np.sqrt(sq.sum())\n",
        "\n",
        "# distance between the points in T1\n",
        "print('Distance between A and B in T1 = ', dist(A1, B1))\n",
        "print('Distance between B and C in T1 = ', dist(B1, C1))\n",
        "print('Distance between A and C in T1 = ', dist(A1, C1))\n",
        "\n",
        "print('')\n",
        "# distnace between the points in T0\n",
        "print('Distance between A and B in T0 = ', dist(A0, B0))\n",
        "print('Distance between B and C in T0 = ', dist(B0, C0))\n",
        "print('Distance between A and C in T0 = ', dist(A0, C0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE95JMniUtDm"
      },
      "source": [
        "We see that in T1, B and C are the closest whereas in T0, A and C are the closest. These kinds of changes will affect the predictions returned by the nearest neighbour algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFbpTSBdV29C"
      },
      "source": [
        "# Transformations on MNIST\n",
        "\n",
        "Let us experiment with a subset of the MNIST dataset. We will extract two features from the database for our experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMvUzC2GUawS"
      },
      "source": [
        "Functions for nearest neighbour, accuracy and feature extraction. (from previous labs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "22ayl0sViF5-"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query  # find the difference between features. Numpy automatically takes care of the size here\n",
        "  sq = diff*diff # square the differences\n",
        "  dist = sq.sum(1) # add up the squares\n",
        "  label = trainlabel[np.argmin(dist)] # our predicted label is the label of the training data which has the least distance from the query\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  # we will run nearest neighbour for each sample in the test data\n",
        "  # and collect the predicted classes in an array using list comprehension\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum() # count the number of times the groundtruth label is equal to the predicted label.\n",
        "  return correct/len(gtlabel)\n",
        "\n",
        "def cumArray(img):\n",
        "  img2 = img.copy()\n",
        "  for ii in range(1, img2.shape[1]):\n",
        "    img2[ii,:] = img2[ii,:] + img2[ii-1,:]  # for every row, add up all the rows above it.\n",
        "  img2 = img2>0\n",
        "  return img2\n",
        "\n",
        "def getHolePixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  hole = hull & ~ (img>0) # remove the original digit to leave behind the holes\n",
        "  return hole\n",
        "\n",
        "def getHullPixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  return hull\n",
        "\n",
        "def minus(a, b):\n",
        "  return a & ~ b\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "  img = img.copy()>0  # binarize the image\n",
        "  rshift = np.roll(img, 1, 1)\n",
        "  lshift = np.roll(img, -1 ,1)\n",
        "  ushift = np.roll(img, -1, 0)\n",
        "  dshift = np.roll(img, 1, 0)\n",
        "  boundary = minus(img, rshift) | minus(img, lshift) | minus(img, ushift) | minus(img, dshift)\n",
        "  return boundary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzF-9mGxUkWC"
      },
      "source": [
        "Get the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHz5BVmLUjzb"
      },
      "outputs": [],
      "source": [
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "nclasses = 4\n",
        "\n",
        "# get only for the first 4 classes\n",
        "train_X = train_X[train_y<nclasses]\n",
        "train_y = train_y[train_y<nclasses]\n",
        "test_X = test_X[test_y<nclasses]\n",
        "test_y = test_y[test_y<nclasses]\n",
        "\n",
        "train_X = train_X[::100].copy() # We are only taking a subset of the training set\n",
        "train_y = train_y[::100].copy() # do the same to the labels\n",
        "test_X = test_X[::100].copy() # taking a subset of the test set. This code takes every 500th sample\n",
        "test_y = test_y[::100].copy()\n",
        "\n",
        "# get all the features\n",
        "train_hole = np.array([getHolePixels(i).sum() for i in train_X])\n",
        "test_hole = np.array([getHolePixels(i).sum() for i in test_X])\n",
        "train_bound = np.array([getBoundaryPixels(i).sum() for i in train_X])\n",
        "test_bound = np.array([getBoundaryPixels(i).sum() for i in test_X])\n",
        "# train_hull = np.array([getHullPixels(i).sum() for i in train_X])\n",
        "# test_hull = np.array([getHullPixels(i).sum() for i in test_X])\n",
        "# train_sum = np.sum(train_X, (1,2))/(28*28)\n",
        "# test_sum = np.sum(test_X, (1,2))/(28*28)\n",
        "\n",
        "# create the train and test set by combining the appropriate features\n",
        "train_feats = np.vstack((train_hole,train_bound)).transpose()\n",
        "test_feats = np.vstack((test_hole, test_bound)).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qGVrlnQCUy"
      },
      "source": [
        "Let us plot the samples and see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saRzHfi9QAGd"
      },
      "outputs": [],
      "source": [
        "# fix limits of x and y axis so that we can see what is going on\n",
        "xlim=[-100,300]\n",
        "ylim=[-100,300]\n",
        "fig, ax = plotData(train_feats, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCb4DikQP1ck"
      },
      "source": [
        "Check the baseline accuracy on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxVr6bd9PzlI"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats, train_y, test_feats)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print('Baseline accuracy = ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl8Noo8pZRek"
      },
      "source": [
        "Let us try transforming the features and checking their accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dUPWRsEZKwo"
      },
      "outputs": [],
      "source": [
        "transform = np.array([[0.5,-0.5],[0,2.5]])\n",
        "\n",
        "train_feats_t = np.matmul(train_feats, transform)\n",
        "test_feats_t = np.matmul(test_feats, transform)  # whatever transform we are applying to the training set should be applied to the test set also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqMBUAfqIUcC"
      },
      "outputs": [],
      "source": [
        "print(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRH4VckHZaWv"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotData(train_feats_t, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9fknczfZdYF"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats_t, train_y, test_feats_t)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print('Accuracy after transform = ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFBQlAnNZ3on"
      },
      "source": [
        "## Questions:\n",
        "1. Experiment with different transformation matrices and check the accuracy\n",
        "2. Will the same transform used for these two features also work for other features?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*ANSWER FOR QUESTION 1*"
      ],
      "metadata": {
        "id": "Xd7HbGtu9dwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.datasets import mnist\n",
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "nclasses = 4\n",
        "\n",
        "# get only for the first 4 classes\n",
        "train_X = train_X[train_y]"
      ],
      "metadata": {
        "id": "rS2JHEoq9kwI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to transform the data"
      ],
      "metadata": {
        "id": "zY4SYVL79nZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tranformDataSet(transform, train_feats, test_feats):\n",
        "  train_feats_t = np.matmul(train_feats, transform)\n",
        "  test_feats_t = np.matmul(test_feats, transform)\n",
        "  return train_feats_t, test_feats_t"
      ],
      "metadata": {
        "id": "B3lxnaV-9py9"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to check accuracy"
      ],
      "metadata": {
        "id": "m8oGCE0R9s7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def checkAccuracy(train_fests_t, test_feats_t, train_y, test_y):\n",
        "  test_pred = NN(train_feats_t, train_y, test_feats_t)\n",
        "  acc = Accuracy(test_y, test_pred)\n",
        "  return acc\n",
        ""
      ],
      "metadata": {
        "id": "m9K8_F8-9vk6"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION TO MAKE APPLY THE TRANSFORMATION AS WELL AS GETTING THE ACCURACY"
      ],
      "metadata": {
        "id": "Whtaz5VE9x3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getAccuracy(train_X, train_y, test_X, test_y, featurelist, transformlist):\n",
        "  listtest = []\n",
        "  listtrain = []\n",
        "  accuracyList = []\n",
        "  # for i in range(-5,6):\n",
        "  #   transformlist.append(np.array([[i, i+1], [i-1, i]]))\n",
        "  for feature in featurelist:\n",
        "    if feature == \"boundary\":\n",
        "      listtrain.append(np.array([getBoundaryPixels(i).sum() for i in train_X]))\n",
        "      listtest.append(np.array([getBoundaryPixels(i).sum() for i in test_X]))\n",
        "    if feature == \"hole\":\n",
        "      listtrain.append(np.array([getHolePixels(i).sum() for i in train_X]))\n",
        "      listtest.append(np.array([getHolePixels(i).sum() for i in test_X]))\n",
        "    if feature == \"hull\":\n",
        "      listtrain.append(np.array([getHullPixels(i).sum() for i in train_X]))\n",
        "      listtest.append(np.array([getHullPixels(i).sum() for i in test_X]))\n",
        "    if feature == \"sum\":\n",
        "      listtrain.append(np.sum(train_X, (1,2))/(28*28))\n",
        "      listtest.append(np.sum(test_X, (1,2))/(28*28))\n",
        "  train_feats = np.vstack(tuple(j for j in listtrain)).transpose()\n",
        "  test_feats = np.vstack(tuple(j for j in listtest)).transpose()\n",
        "  # train_fests_t, test_feats_t = tranformDataSet(np.array([[0.5,-0.5],[0,2.5]]), train_feats, test_feats)\n",
        "  # accuracyList.append(checkAccuracy(train_fests_t, test_feats_t, train_y, test_y))\n",
        "  for i in transformlist:\n",
        "    train_fests_t, test_feats_t = tranformDataSet(i, train_feats, test_feats)\n",
        "    accuracyList.append(checkAccuracy(train_fests_t, test_feats_t, train_y, test_y))\n",
        "  return accuracyList"
      ],
      "metadata": {
        "id": "oLARIsii91BV"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW LET US CHECK FOR ACCURACIES OBTAINED FOR DIFFERENT VALUES OF TRANSFORMATION MATRICES"
      ],
      "metadata": {
        "id": "IQjslJEU94Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "featurelist = ['hole','boundary']\n",
        "transformlist = [np.array([[0.25,-0.25],[0,4.5]]),\n",
        "                 np.array([[0.85,-0.25], [0, 4.0]]),\n",
        "                 np.array([[1,-0.25], [0, 4.0]]),\n",
        "                 np.array([[0.25,-0.25], [0, 4.0]]),\n",
        "                 np.array([[0.25,-0.85], [0, 4.5]]),\n",
        "                 np.array([[0.25,-0.25], [0, 3.0]]),\n",
        "                 np.array([[0.25,-0.25],[0,-4.5]]),\n",
        "                 np.array([[-0.25,-0.25],[0,-4.5]]),\n",
        "                 ]\n",
        "accuracyList = getAccuracy(train_X, train_y, test_X, test_y, featurelist, transformlist)\n",
        "for i in range(len(transformlist)):\n",
        "  print(f\"matrics = {transformlist[i]} accuracy = {accuracyList[i]}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "dEESPIFk96lA",
        "outputId": "a1d8f817-958e-40d8-aa53-679925b9865c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.    4.5 ]] accuracy = 0.1422\n",
            "matrics = [[ 0.85 -0.25]\n",
            " [ 0.    4.  ]] accuracy = 0.0992\n",
            "matrics = [[ 1.   -0.25]\n",
            " [ 0.    4.  ]] accuracy = 0.1003\n",
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.    4.  ]] accuracy = 0.0933\n",
            "matrics = [[ 0.25 -0.85]\n",
            " [ 0.    4.5 ]] accuracy = 0.1423\n",
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.    3.  ]] accuracy = 0.1312\n",
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.   -4.5 ]] accuracy = 0.1028\n",
            "matrics = [[-0.25 -0.25]\n",
            " [ 0.   -4.5 ]] accuracy = 0.1028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that for different values of the transformation matrix the accuracies are different. With the highest values obtained for given matrix and some of the variants that I tried. The accuracy is very sensitive with boundary values as when i tried changing them the accuracy decrease drastically."
      ],
      "metadata": {
        "id": "h2XNVBMG9-Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*ANSWER FOR QUESTION 2*"
      ],
      "metadata": {
        "id": "0_C9q1KJ-A5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featurelist = [\"hull\",'sum']\n",
        "transformlist = [np.array([[0.25,-0.25],[0,2.5]]),\n",
        "                 np.array([[0.85,-0.25], [0, 2.0]]),\n",
        "                 np.array([[1,-0.25], [0, 2.0]]),\n",
        "                 np.array([[0.25,-0.25], [0, 2.0]]),\n",
        "                 np.array([[0.25,-0.85], [0, 2.5]]),\n",
        "                 np.array([[0.25,-0.25], [0, 3.0]]),\n",
        "                 np.array([[0.25,-0.25],[0,-2.5]]),\n",
        "                 np.array([[30,20],[0,-20.5]]),\n",
        "                 ]\n",
        "accuracyList = getAccuracy(train_X, train_y, test_X, test_y, featurelist, transformlist)\n",
        "for i in range(len(transformlist)):\n",
        "  print(f\"matrics = {transformlist[i]} accuracy = {accuracyList[i]}\")\n"
      ],
      "metadata": {
        "id": "GYSNLNcS-KGU",
        "outputId": "ac8bb864-2dbc-4566-97b9-17f244620358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.    2.5 ]] accuracy = 0.1028\n",
            "matrics = [[ 0.85 -0.25]\n",
            " [ 0.    2.  ]] accuracy = 0.1113\n",
            "matrics = [[ 1.   -0.25]\n",
            " [ 0.    2.  ]] accuracy = 0.1633\n",
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.    2.  ]] accuracy = 0.1028\n",
            "matrics = [[ 0.25 -0.85]\n",
            " [ 0.    2.5 ]] accuracy = 0.1028\n",
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.    3.  ]] accuracy = 0.1028\n",
            "matrics = [[ 0.25 -0.25]\n",
            " [ 0.   -2.5 ]] accuracy = 0.1028\n",
            "matrics = [[ 30.   20. ]\n",
            " [  0.  -20.5]] accuracy = 0.1009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36TOA47xak20"
      },
      "source": [
        "# Data normalization\n",
        "\n",
        "Sometimes the features of our data have vastly different scales. This will cause the learning algorithm to give more importance to certain features, reducing its performance. Data normalization is a method in which we transform the features so that they have similar scales.\n",
        "\n",
        "Three commonly used feature scaling techniques are rescaling, mean normalization and z-score normalization. Here, we will talk about the simplest one: rescaling.\n",
        "\n",
        "$$\\begin{equation}\n",
        "x' = \\frac {x -min(x)} { max(x) - min(x)}\n",
        "\\end{equation}$$\n",
        "\n",
        "\n",
        "\n",
        "For more information, see [this page](https://towardsdatascience.com/data-normalization-in-machine-learning-395fdec69d02)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni19QKDLZzeo"
      },
      "outputs": [],
      "source": [
        "def rescale(data):\n",
        "  return (data - data.min())/(data.max() - data.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k83ZMtKeZrQ"
      },
      "source": [
        "We have to apply the rescaling to each feature individually. Also remember to apply the same transform we are using on the train set to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JLOPwhvehpR"
      },
      "outputs": [],
      "source": [
        "train_feats_rescaled_x = rescale(train_feats[:,0])\n",
        "train_feats_rescaled_y = rescale(train_feats[:,1])\n",
        "train_feats_rescaled = np.stack((train_feats_rescaled_x, train_feats_rescaled_y),1)\n",
        "\n",
        "test_feats_rescaled_x = rescale(test_feats[:,0])\n",
        "test_feats_rescaled_y = rescale(test_feats[:,1])\n",
        "test_feats_rescaled = np.stack((test_feats_rescaled_x, test_feats_rescaled_y),1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaZVy9vxfKwX"
      },
      "source": [
        "Let us plot the rescaled features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXyatpwZevOH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotData(train_feats_rescaled, train_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBgxE6zglsL"
      },
      "source": [
        "This type of rescaling makes all the features between 0 and 1.\n",
        "\n",
        "Let us calculate the accuracy obtained by this transform:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKQnsj-KgNZc"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats_rescaled, train_y, test_feats_rescaled)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print('Accuracy after transform = ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYX90Gqg-jO"
      },
      "source": [
        "All 2D linear transformations can be repreented by a transformation matrix. So what is the matrix associated with the rescaling function? Actually, we cannot represent rescaling with a matrix multiplication, because it is not a linear transform. Rescaling involves shifting the origin of the data, which is not allowed under linear transformations.\n",
        "\n",
        "We can represent rescaling as a matrix multiplication followed by a vector addition. Let our first feature vector be called X and second feature vector be called Y. Suppose we want to rescale a data point [a,b]\n",
        "\n",
        "$$ \\begin{equation}\n",
        " \\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned} \\frac{a - min(X)}{max(X) - min(X)} \\\\ \\frac{b - min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned}&\\frac{1}{max(X)-min(X)} &0\\\\ &0 &\\frac{1}{max(Y)-min(Y)} \\end{aligned}\n",
        " \\right\\}\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\} +\n",
        " \\left\\{  \\begin{aligned} \\frac{ -min(X)}{max(X) - min(X)} \\\\ \\frac{-min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "\n",
        "You can verify this yourself if you wish, though it is not necessary.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}